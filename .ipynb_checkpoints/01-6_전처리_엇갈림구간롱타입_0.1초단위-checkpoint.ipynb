{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86671937-3fc4-491a-8b3d-e230d658229a",
   "metadata": {},
   "source": [
    "# Longtype\n",
    "* 차량 쌍(TV, LV) 기준으로 정리하기\n",
    "* 왜냐하면, 각 쌍별로 SSM이 계산되기 때문임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296ec39-7aba-465c-b204-22e70c86aaf3",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617b939a-52ee-4b0b-aca0-e4281b4478d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:22.207979Z",
     "iopub.status.busy": "2023-12-01T00:56:22.207979Z",
     "iopub.status.idle": "2023-12-01T00:56:23.156930Z",
     "shell.execute_reply": "2023-12-01T00:56:23.155938Z",
     "shell.execute_reply.started": "2023-12-01T00:56:22.207979Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "from scipy import stats # Z-score를 이용한 이상값 제거\n",
    "\n",
    "import math # arctangent; math.atan 사용 목적\n",
    "import statistics\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "#df = pq.read_pandas('data.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d84bf7-ac0f-456a-9650-c0b846280279",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025f8acc-6100-48d1-89e7-5a7d87c9512a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:23.157898Z",
     "iopub.status.busy": "2023-12-01T00:56:23.157898Z",
     "iopub.status.idle": "2023-12-01T00:56:23.171885Z",
     "shell.execute_reply": "2023-12-01T00:56:23.171885Z",
     "shell.execute_reply.started": "2023-12-01T00:56:23.157898Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = 'D:/OneDrive/Projects/2023_SSM_Feasibility/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc96224-9229-48a1-8eb7-2ae8b979de63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:23.172887Z",
     "iopub.status.busy": "2023-12-01T00:56:23.172887Z",
     "iopub.status.idle": "2023-12-01T00:56:23.187846Z",
     "shell.execute_reply": "2023-12-01T00:56:23.186846Z",
     "shell.execute_reply.started": "2023-12-01T00:56:23.172887Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list = ['LV_trajectories-0750am-0805am.parquet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b2f8e8-ebe2-478b-b9d7-26ce8addf72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:23.188818Z",
     "iopub.status.busy": "2023-12-01T00:56:23.187846Z",
     "iopub.status.idle": "2023-12-01T00:56:24.704491Z",
     "shell.execute_reply": "2023-12-01T00:56:24.703244Z",
     "shell.execute_reply.started": "2023-12-01T00:56:23.188818Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_name = '02_processed'\n",
    "\n",
    "for file, i in zip(file_list, [1]):\n",
    "    file_path = os.path.join(working_dir, folder_name, file)\n",
    "    globals()[f'df_{i}'] = pq.read_pandas(file_path).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30783299-8876-4eb5-9117-445dfc0f8bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:24.706850Z",
     "iopub.status.busy": "2023-12-01T00:56:24.705858Z",
     "iopub.status.idle": "2023-12-01T00:56:24.734653Z",
     "shell.execute_reply": "2023-12-01T00:56:24.734653Z",
     "shell.execute_reply.started": "2023-12-01T00:56:24.706850Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>veh_id</th>\n",
       "      <th>frm</th>\n",
       "      <th>local_y</th>\n",
       "      <th>local_x</th>\n",
       "      <th>V_len</th>\n",
       "      <th>V_wid</th>\n",
       "      <th>velocity</th>\n",
       "      <th>acc</th>\n",
       "      <th>lane</th>\n",
       "      <th>Preceeding</th>\n",
       "      <th>...</th>\n",
       "      <th>LVR_delta_velocity_y</th>\n",
       "      <th>LVR_acc_x</th>\n",
       "      <th>LVR_acc_y</th>\n",
       "      <th>LVR_Lane_record</th>\n",
       "      <th>LVR_Lane_record_split</th>\n",
       "      <th>LVR_Lane_change_direction</th>\n",
       "      <th>LV0_D</th>\n",
       "      <th>LVL_D</th>\n",
       "      <th>LVR_D</th>\n",
       "      <th>LC_CF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>17.375000</td>\n",
       "      <td>10.78125</td>\n",
       "      <td>4.417969</td>\n",
       "      <td>1.493164</td>\n",
       "      <td>43.90625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>-0.002352</td>\n",
       "      <td>U04</td>\n",
       "      <td>U04_U04</td>\n",
       "      <td>Straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.132812</td>\n",
       "      <td>LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>17.375000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>4.417969</td>\n",
       "      <td>1.493164</td>\n",
       "      <td>43.90625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>U04</td>\n",
       "      <td>U04_U04</td>\n",
       "      <td>Straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>LC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>17.390625</td>\n",
       "      <td>13.21875</td>\n",
       "      <td>4.417969</td>\n",
       "      <td>1.493164</td>\n",
       "      <td>43.90625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>U04</td>\n",
       "      <td>U04_U04</td>\n",
       "      <td>Straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.132812</td>\n",
       "      <td>LC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       veh_id  frm    local_y   local_x     V_len     V_wid  velocity  acc  \\\n",
       "index                                                                        \n",
       "0           2   13  17.375000  10.78125  4.417969  1.493164  43.90625  0.0   \n",
       "1           2   14  17.375000  12.00000  4.417969  1.493164  43.90625  0.0   \n",
       "2           2   15  17.390625  13.21875  4.417969  1.493164  43.90625  0.0   \n",
       "\n",
       "      lane  Preceeding  ...  LVR_delta_velocity_y  LVR_acc_x  LVR_acc_y  \\\n",
       "index                   ...                                               \n",
       "0      U02           0  ...             -0.000847   0.004704  -0.002352   \n",
       "1      U02           0  ...              0.000000  -0.002352   0.000000   \n",
       "2      U02           0  ...              0.001694  -0.000000   0.004704   \n",
       "\n",
       "       LVR_Lane_record  LVR_Lane_record_split  LVR_Lane_change_direction  \\\n",
       "index                                                                      \n",
       "0                  U04                U04_U04                   Straight   \n",
       "1                  U04                U04_U04                   Straight   \n",
       "2                  U04                U04_U04                   Straight   \n",
       "\n",
       "       LV0_D  LVL_D      LVR_D  LC_CF  \n",
       "index                                  \n",
       "0        NaN    NaN  10.132812     LC  \n",
       "1        NaN    NaN  10.125000     LC  \n",
       "2        NaN    NaN  10.132812     LC  \n",
       "\n",
       "[3 rows x 108 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b09190-eade-4e86-8d1e-c98b1701d145",
   "metadata": {},
   "source": [
    "# Longtype\n",
    "* pairs 리스트의 튜플(TV, LV)에 따라서 각 차량의 위치, 속도, 가속도 등을 df로부터 프레임별로 뽑아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662aa1d3-5ac3-4fdd-83f6-ce1cbca81778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:24.736158Z",
     "iopub.status.busy": "2023-12-01T00:56:24.736158Z",
     "iopub.status.idle": "2023-12-01T00:56:25.033898Z",
     "shell.execute_reply": "2023-12-01T00:56:25.032901Z",
     "shell.execute_reply.started": "2023-12-01T00:56:24.736158Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for df, i in tqdm(zip([df_1], [1])):\n",
    "\n",
    "    df_LV0 = df[['veh_id', 'LV0_ID', 'frm']].copy()\n",
    "    df_LV0 = df_LV0.rename({'LV0_ID' : 'LV_ID'}, axis =1)\n",
    "    df_LV0['LV_type'] = 'LV0'\n",
    "    \n",
    "    df_LVL = df[['veh_id', 'LVL_ID', 'frm']].copy()\n",
    "    df_LVL = df_LVL.rename({'LVL_ID' : 'LV_ID'}, axis = 1)\n",
    "    df_LVL['LV_type'] = 'LVL'\n",
    "\n",
    "    df_LVR = df[['veh_id', 'LVR_ID', 'frm']].copy()\n",
    "    df_LVR = df_LVR.rename({'LVR_ID' : 'LV_ID'}, axis = 1)\n",
    "    df_LVR['LV_type'] = 'LVR'\n",
    "    \n",
    "    total_long = pd.concat([df_LV0, df_LVL, df_LVR])\n",
    "    \n",
    "    # LV_ID가 0인 것은 제거한다\n",
    "    total_long = total_long[(total_long['LV_ID'] != 0) & (pd.isna(total_long['LV_ID']) == False)]\n",
    "    total_long['LV_ID'] = total_long['LV_ID'].astype('int')\n",
    "    total_long.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    globals()[f'long_{i}'] = total_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02725080-54df-4a1a-ac9b-7b6f581a0f84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:25.034896Z",
     "iopub.status.busy": "2023-12-01T00:56:25.034896Z",
     "iopub.status.idle": "2023-12-01T00:56:25.187849Z",
     "shell.execute_reply": "2023-12-01T00:56:25.187849Z",
     "shell.execute_reply.started": "2023-12-01T00:56:25.034896Z"
    }
   },
   "outputs": [],
   "source": [
    "veh_pair = long_1[['veh_id', 'LV_ID']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3cb0cd-9628-499b-b38e-d699bc0aa363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:25.189815Z",
     "iopub.status.busy": "2023-12-01T00:56:25.188839Z",
     "iopub.status.idle": "2023-12-01T00:56:25.202802Z",
     "shell.execute_reply": "2023-12-01T00:56:25.202802Z",
     "shell.execute_reply.started": "2023-12-01T00:56:25.189815Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_int(x):\n",
    "    if pd.isna(x) == False:\n",
    "        return int(x)\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e81de30-e7a7-4f01-81bb-a2caaf97ba09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:25.204777Z",
     "iopub.status.busy": "2023-12-01T00:56:25.204777Z",
     "iopub.status.idle": "2023-12-01T00:56:25.218735Z",
     "shell.execute_reply": "2023-12-01T00:56:25.217737Z",
     "shell.execute_reply.started": "2023-12-01T00:56:25.204777Z"
    }
   },
   "outputs": [],
   "source": [
    "def RL0(lane, LV_lane):\n",
    "    if pd.isna(lane) == False and pd.isna(LV_lane) == False:\n",
    "        lane_num = int(lane[1:])\n",
    "        LV_lane_num = int(LV_lane[1:])\n",
    "\n",
    "        if lane_num == LV_lane_num:\n",
    "            type_LV = 'LV0'\n",
    "            \n",
    "        elif lane_num < LV_lane_num:\n",
    "            type_LV = 'LVR'\n",
    "            \n",
    "        elif lane_num > LV_lane_num:\n",
    "            type_LV = 'LVL'\n",
    "\n",
    "        else:\n",
    "            type_LV = None\n",
    "\n",
    "    else:\n",
    "        type_LV = None\n",
    "\n",
    "    return type_LV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7a3c96-1caa-453a-bcd0-e32eace660bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T00:56:25.219733Z",
     "iopub.status.busy": "2023-12-01T00:56:25.219733Z",
     "iopub.status.idle": "2023-12-01T01:58:05.639877Z",
     "shell.execute_reply": "2023-12-01T01:58:05.638879Z",
     "shell.execute_reply.started": "2023-12-01T00:56:25.219733Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 44278/44278 [1:01:40<00:00, 11.97it/s]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "target_df_cols = ['local_x', 'local_y', 'V_len', 'V_wid', 'velocity', 'acc', 'lane', 'Time',\n",
    "                  'local_x_before', 'local_y_before', 'delta_local_x', 'delta_local_y',\n",
    "                  'velocity_x', 'velocity_y', 'velocity_x_before', 'velocity_y_before', 'delta_velocity_x', 'delta_velocity_y',\n",
    "                  'acc_x', 'acc_y', 'lane_past', 'Lane_record', 'Lane_record_split', 'Lane_00', 'Lane_99',\n",
    "                  'Lane_change', 'Lane_leave', 'Lane_change_direction', 'LC_CF']\n",
    "\n",
    "column_order = ['pair', 'veh_id', 'LV_ID', 'frm', 'LV_type', 'local_x', 'local_y', 'V_len', 'V_wid', 'velocity',\n",
    "       'acc', 'lane', 'Time', 'local_x_before', 'local_y_before',\n",
    "       'delta_local_x', 'delta_local_y', 'velocity_x', 'velocity_y',\n",
    "       'velocity_x_before', 'velocity_y_before', 'delta_velocity_x',\n",
    "       'delta_velocity_y', 'acc_x', 'acc_y', 'lane_past', 'Lane_record',\n",
    "       'Lane_record_split', 'Lane_00', 'Lane_99', 'Lane_change', 'Lane_leave',\n",
    "       'Lane_change_direction', 'LC_CF', 'LV_local_x',\n",
    "       'LV_local_y', 'LV_len', 'LV_wid', 'LV_velocity', 'LV_acc', 'LV_lane',\n",
    "       'LV_Time', 'LV_local_x_before', 'LV_local_y_before', 'LV_delta_local_x',\n",
    "       'LV_delta_local_y', 'LV_velocity_x', 'LV_velocity_y',\n",
    "       'LV_velocity_x_before', 'LV_velocity_y_before', 'LV_delta_velocity_x',\n",
    "       'LV_delta_velocity_y', 'LV_acc_x', 'LV_acc_y', 'LV_lane_past',\n",
    "       'LV_Lane_record', 'LV_Lane_record_split', 'LV_Lane_00', 'LV_Lane_99',\n",
    "       'LV_Lane_change', 'LV_Lane_leave', 'LV_Lane_change_direction',\n",
    "       'LV_LC_CF', 'D_x', 'D_y', 'D', 'D_gap']\n",
    "\n",
    "\n",
    "##### 엇갈림구간 임시저장폴더 : 02_temp_weave ########\n",
    "# 차량별로 저장 후 concat은 일괄수행해야 한다.\n",
    "\n",
    "#### 차량 페어링하기기\n",
    "for long, i in zip([long_1], [1]):\n",
    "\n",
    "    # 레퍼런스 데이터프레임\n",
    "    reference_df = globals()[f'df_{i}'][['veh_id', 'frm'] + target_df_cols].copy() # Merge의 reference가 될 데이터프레임\n",
    "    veh_list = list(reference_df['veh_id'].unique())\n",
    "\n",
    "    veh_tot = pd.DataFrame()\n",
    "    \n",
    "    for i in tqdm(range(len(veh_pair))): # 각 차량에 대하여\n",
    "        row = veh_pair.iloc[i] # 차량 쌍\n",
    "        veh_id = row['veh_id']\n",
    "        LV_ID = row['LV_ID']\n",
    "        #LV_type = row['LV_type']\n",
    "\n",
    "        veh_TV = reference_df[reference_df['veh_id'] == veh_id].copy()\n",
    "        veh_LV = reference_df[reference_df['veh_id'] == LV_ID].copy()\n",
    "\n",
    "        # LV 데이터프레임 컬럼이름을 적절하게 변경\n",
    "        for col in target_df_cols:\n",
    "            veh_LV = veh_LV.rename({col : 'LV_'+col}, axis = 1)\n",
    "\n",
    "        veh_LV.rename({'LV_V_len' : 'LV_len', 'LV_V_wid' : 'LV_wid'}, axis = 1, inplace = True)\n",
    "\n",
    "        veh_TV['LV_ID'] = LV_ID\n",
    "        #veh_TV['LV_type'] = LV_type\n",
    "        veh_tot = pd.merge(veh_TV, veh_LV, how = 'left', left_on = ['LV_ID', 'frm'], right_on = ['veh_id', 'frm']).rename({'veh_id_x' : 'veh_id'}, axis = 1).drop(['veh_id_y'], axis = 1)\n",
    "        pair_id = str(veh_id) + '_' + str(LV_ID)\n",
    "\n",
    "        veh_tot['pair'] = pair_id\n",
    "\n",
    "        # LV_type 매기기\n",
    "        veh_tot['LV_type'] = veh_tot.apply(lambda row: RL0(row['lane'], row['LV_lane']), axis = 1)\n",
    "\n",
    "        # 거리관련 변수\n",
    "        veh_tot['D_x'] = veh_tot['LV_local_x'] - veh_tot['local_x']\n",
    "        veh_tot['D_y'] = veh_tot['LV_local_y'] - veh_tot['local_y']\n",
    "        veh_tot['D'] = (veh_tot['D_x']**2 + veh_tot['D_y']**2) ** (1/2)\n",
    "        veh_tot.reset_index(inplace = True, drop = True)\n",
    "        \n",
    "        veh_tot['D_lag'] = veh_tot['D'].shift(1) # 직전 row의 값임\n",
    "        veh_tot['veh_id'] = veh_tot['veh_id'].astype('int')\n",
    "        veh_tot['LV_ID'] = veh_tot['LV_ID'].apply(make_int)\n",
    "        veh_tot['frm'] = veh_tot['frm'].astype('int')\n",
    "        \n",
    "        #veh_tot['veh_id_lag'] = veh_tot['veh_id'].shift(1) # 직전 row 값\n",
    "        #veh_tot['LV_ID_lag'] = veh_tot['LV_ID'].shift(1) # 직전 row 값\n",
    "        \n",
    "        veh_tot['D_gap'] = veh_tot['D'] - veh_tot['D_lag'] # 거리 변화. (-)이면 줄어들고 있다는 뜻이다\n",
    "        \n",
    "        # 만약 veh_id, LV_id 의 lag값이 현재 row와 다르다면, 새로운 값이 시작된 것이므로 D_gap을 NaN으로 만들어줘야 한다.\n",
    "        #veh_tot.loc[(veh_tot['veh_id'] != veh_tot['veh_id_lag']) | (veh_tot['LV_ID'] != veh_tot['LV_ID_lag']), 'D_gap'] = None\n",
    "        \n",
    "        #print(f'{i} : {len(long_final)}')\n",
    "        veh_tot.drop(['D_lag'], axis = 1, inplace = True)\n",
    "        veh_tot = veh_tot[column_order]\n",
    "        veh_tot = veh_tot.sort_values(by = 'pair').reset_index(drop = True)        \n",
    "\n",
    "        temp_save_name = f'{pair_id}_weave.parquet'\n",
    "        temp_save_path = os.path.join(working_dir, '02_weave_temp', temp_save_name)\n",
    "        veh_tot.to_parquet(temp_save_path, engine = 'fastparquet', compression = 'gzip') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4cdba-e18c-4f76-8c5c-ce0b577a94cf",
   "metadata": {},
   "source": [
    "* ** Merge Small Parquet to Huge Parquet** : https://stackoverflow.com/questions/75468395/merge-small-parquet-files-into-a-single-large-parquet-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d71a7103-e825-4fc0-bb0e-477b70c942ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T01:58:13.326680Z",
     "iopub.status.busy": "2023-12-01T01:58:13.325682Z",
     "iopub.status.idle": "2023-12-01T01:58:13.338650Z",
     "shell.execute_reply": "2023-12-01T01:58:13.337651Z",
     "shell.execute_reply.started": "2023-12-01T01:58:13.326680Z"
    }
   },
   "outputs": [],
   "source": [
    "#### 굳이 수행하지 않아도 되는 병합코드. 이건 나중에 한다.\n",
    "\n",
    "# save_folder = '02_processed_long'\n",
    "# save_files = ['LV_long_trajectories-0750am-0805am.parquet']\n",
    "\n",
    "# file_list = os.listdir(os.path.join(working_dir, '02_weave_temp'))\n",
    "\n",
    "# save_path = os.path.join(working_dir, save_folder, save_files[0])\n",
    "\n",
    "# schema_path = os.path.join(working_dir, '02_weave_temp', file_list[0])\n",
    "# schema = pq.ParquetFile(schema_path).schema_arrow\n",
    "\n",
    "# save_path = os.path.join(working_dir, save_folder, save_files[0])\n",
    "\n",
    "# with pq.ParquetWriter(save_path, schema = schema) as writer:\n",
    "#     for file in tqdm(file_list):\n",
    "#         file_path = os.path.join(working_dir, '02_weave_temp', file)\n",
    "#         writer.write_table(pq.read_table(file_path, schema = schema))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
