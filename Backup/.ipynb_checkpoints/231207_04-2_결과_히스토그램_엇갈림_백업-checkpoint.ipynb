{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6195b8-d5ee-4f49-8b81-1c852a8c8419",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "* 대상지 주요 정보 정리(교통량, 속도, 차로변경 등)\n",
    "* 시각화\n",
    "    * 히스토그램 & 바이올린 플롯(집계적)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcbe99-99a3-4aac-9121-b5f98253c717",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be8261ae-30fc-4f98-ab4f-8d7eaab22b23",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "#import ray\n",
    "#ray.shutdown()\n",
    "#ray.init() # 병렬 처리를 위한 클러스터 구축\n",
    "#import modin.pandas as pd\n",
    "\n",
    "import math # arctangent; math.atan 사용 목적\n",
    "import statistics\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as po\n",
    "\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib as mpl\n",
    "from matplotlib.text import Annotation\n",
    "\n",
    "from SSM_base import points\n",
    "\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ea0a8-ba56-4d84-a46f-01e078a75b17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f714b3ad-eed2-4896-9c76-c40066438706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = 'D:/OneDrive/Projects/2023_SSM_Feasibility'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6095b9-16bb-44ca-a310-003287d711b9",
   "metadata": {},
   "source": [
    "# 이미지 폰트 깨지는거 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d82f5e-9c5d-4b4a-88b9-786712378a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a925472-fcc5-4c13-82e5-cf5887640ed8",
   "metadata": {},
   "source": [
    "# 임계값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed721461-1007-41e5-a43b-eeab5025e8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_name = 'Documents'\n",
    "file_name = 'SSM_threshold.csv'\n",
    "sheet_name = 'threshold'\n",
    "\n",
    "threshold_path = os.path.join(working_dir, folder_name, file_name)\n",
    "\n",
    "threshold_list = np.array(pandas.read_csv(threshold_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c985159-929a-4c69-b8d5-9c606c77b976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['TTC', 3.0],\n",
       "       ['ITTC', 0.33],\n",
       "       ['T2', 3.0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa0db3-f888-4182-ac14-7003957626d9",
   "metadata": {},
   "source": [
    "## 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036f47ab-549c-4546-8e0b-34cd9398bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스키마 불러오기\n",
    "schema_folder = 'Dataset/03_SSM_weave_temp'\n",
    "schema_file = '2640_2631_weave.parquet'\n",
    "schema_path = os.path.join(working_dir, schema_folder, schema_file)\n",
    "schema = pandas.read_parquet(schema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43013459-7a8d-4760-939a-dfd3b67eac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pair', 'veh_id', 'LV_ID', 'frm', 'LV_type', 'local_x', 'local_y',\n",
       "       'V_len', 'V_wid', 'velocity', 'acc', 'lane', 'Time', 'local_x_before',\n",
       "       'local_y_before', 'delta_local_x', 'delta_local_y', 'velocity_x',\n",
       "       'velocity_y', 'velocity_x_before', 'velocity_y_before',\n",
       "       'delta_velocity_x', 'delta_velocity_y', 'acc_x', 'acc_y', 'lane_past',\n",
       "       'Lane_record', 'Lane_record_split', 'Lane_00', 'Lane_99', 'Lane_change',\n",
       "       'Lane_leave', 'Lane_change_direction', 'LC_CF', 'LV_local_x',\n",
       "       'LV_local_y', 'LV_len', 'LV_wid', 'LV_velocity', 'LV_acc', 'LV_lane',\n",
       "       'LV_Time', 'LV_local_x_before', 'LV_local_y_before', 'LV_delta_local_x',\n",
       "       'LV_delta_local_y', 'LV_velocity_x', 'LV_velocity_y',\n",
       "       'LV_velocity_x_before', 'LV_velocity_y_before', 'LV_delta_velocity_x',\n",
       "       'LV_delta_velocity_y', 'LV_acc_x', 'LV_acc_y', 'LV_lane_past',\n",
       "       'LV_Lane_record', 'LV_Lane_record_split', 'LV_Lane_00', 'LV_Lane_99',\n",
       "       'LV_Lane_change', 'LV_Lane_leave', 'LV_Lane_change_direction',\n",
       "       'LV_LC_CF', 'D_x', 'D_y', 'D', 'D_gap', 'new_local_x', 'new_local_y',\n",
       "       'new_LV_local_x', 'new_LV_local_y', 'overlap',\n",
       "       'potential_conflict_type', 'degX', 'T2', 'TTC', 'MTTC', 'CI_MTTC',\n",
       "       'ACT', 'pPET', 'time_gap', 'PSD', 'DSS', 'PICUD', 'MTC', 'MMTC', 'DRAC',\n",
       "       'MDRAC', 'DCIA', 'unsafety', 'TIT', 'TIT2', 'TIACT', 'TITAdv',\n",
       "       'TITimeGap', 'TIPICUD', 'TIDSS', 'TIDRAC', 'TIMDRAC', 'TIDCIA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "567aa6e3-6986-459c-b1ae-2f79da3e17b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "var_list = ['velocity', 'acc']\n",
    "SSM_list_1 = [ 'TTC', 'MTTC', 'T2', 'TAdv', 'TimeGap', 'ACT']\n",
    "SSM_list_2 = ['PSD', 'DSS', 'MMTC', 'PICUD', 'MTC']\n",
    "SSM_list_3 = ['DRAC', 'MDRAC', 'DCIA', 'unsafety']\n",
    "\n",
    "SSM_list = SSM_list_1 + SSM_list_2 + SSM_list_3\n",
    "\n",
    "print(len(SSM_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b6f558-16c5-4153-9f82-50aaf730b1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_cell(local_x):\n",
    "    \"\"\"\n",
    "    Local X (m) 변수값에 따른 셀 번호 지정\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(local_x) == False:\n",
    "        cellnum = int(local_x//20 + 1) # 나머지는 버린다.\n",
    "        cellnum = cellnum * 20\n",
    "    \n",
    "        if cellnum < 100:\n",
    "            cell = '0' + str(cellnum)\n",
    "\n",
    "        else: # cellnum >= 10인 경우\n",
    "            cell = str(cellnum)    \n",
    "            \n",
    "    else:\n",
    "        cell = None\n",
    "        \n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af7e0376-7779-4db3-ae75-998f149c0aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_to_plotly(pv):\n",
    "    return {'z': pv.values.tolist(),\n",
    "            'y': pv['lane'].tolist(),\n",
    "            'x': pv.columns.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f64c688d-097e-47d2-b09d-8db9b802376e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "palette_ryb = ['#00b0f0', '#ffff00', '#ff5050'] # 엇갈림구간 프로젝트의 그 삼색팔레트 : 파랑-노랑-빨강\n",
    "palette_TIT = ['#ffffff', '#ff0000'] # 환색~빨강\n",
    "#palette_bluewhite = ['#ffffff', '#0054ff'] # \n",
    "palette_TTC = ['#ff0000', '#ffffff'] # 빨강~흰색\n",
    "#palette_whiteblue = ['#0054ff', '#ffffff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f6b1d3e-2166-4355-9aac-50ed050d7f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_folder = 'Dataset/03_SSM'\n",
    "long_file = 'long_squeeze_trajectories-0750am-0805am.parquet'\n",
    "long_path = os.path.join(working_dir, long_folder, long_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7dc4e3d-d4e6-4c79-b153-198cae5513ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in ['TTC', 'MTTC', 'T2', 'ACT', 'pPET', 'time_gap']:\n",
    "#     df_0.loc[df_0[col] == math.inf, col] = np.nan\n",
    "\n",
    "# df_0.rename({'time_gap' : 'TimeGap', 'pPET':'TAdv'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a89ce3-1476-4079-ad31-34b7bf6d63a4",
   "metadata": {},
   "source": [
    "# 주요포인트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a3f5f-e3e7-4c0c-adfd-9ccc0439586f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 기초통계량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d54ea-e423-48e5-a784-2152224f0ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "long_folder = 'Dataset/03_SSM'\n",
    "long_file = 'long_trajectories-0750am-0805am.parquet'\n",
    "long_path = os.path.join(working_dir, long_folder, long_file)\n",
    "df = dd.read_parquet(long_path)\n",
    "\n",
    "category_col_list = ['pair', 'veh_id', 'LV_ID', 'LV_type', 'lane', 'lane_past',\n",
    "                     'Lane_record', 'Lane_record_split', 'Lane_00', 'Lane_99', \n",
    "                     'Lane_change', 'Lane_leave', 'Lane_change_direction', 'LC_CF', \n",
    "                     'LV_lane', 'LV_lane_past', 'LV_Lane_record', 'LV_Lane_record_split', \n",
    "                     'LV_Lane_00', 'LV_Lane_99', 'LV_Lane_change', 'LV_Lane_leave', 'LV_Lane_change_direction', 'LV_LC_CF', \n",
    "                     'overlap', 'potential_conflict_type']\n",
    "\n",
    "for col in tqdm(category_col_list):\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "df.rename({'time_gap' : 'TimeGap', 'pPET':'TAdv'}, axis = 1, inplace = True)\n",
    "\n",
    "# long_folder = 'Dataset/03_SSM'\n",
    "# long_file = 'long_squeeze_trajectories-0750am-0805am.parquet'\n",
    "# long_path = os.path.join(working_dir, long_folder, long_file)\n",
    "\n",
    "# df.to_parquet(long_path, engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0246dbec-1319-472c-a6ba-b706055f2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'time_gap' : 'TimeGap', 'pPET':'TAdv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9bc6f90f-8341-41b9-a0cb-c040afaa1f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TTC',\n",
       " 'MTTC',\n",
       " 'T2',\n",
       " 'TAdv',\n",
       " 'TimeGap',\n",
       " 'ACT',\n",
       " 'PSD',\n",
       " 'DSS',\n",
       " 'MMTC',\n",
       " 'PICUD',\n",
       " 'MTC',\n",
       " 'DRAC',\n",
       " 'MDRAC',\n",
       " 'DCIA',\n",
       " 'unsafety']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSM_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc9da44d-526c-490c-8118-ba29ad67c56c",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLC_CF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpotential_conflict_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mpivot_table(\n\u001b[0;32m      4\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLC_CF\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotential_conflict_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     values \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTTC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMTTC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAdv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeGap\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACT\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDSS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMMTC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPICUD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMTC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDRAC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMDRAC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDCIA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafety\u001b[39m\u001b[38;5;124m'\u001b[39m}, \n\u001b[0;32m      8\u001b[0m     aggfunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\core.py:5518\u001b[0m, in \u001b[0;36mDataFrame.categorize\u001b[1;34m(self, columns, index, split_every, **kwargs)\u001b[0m\n\u001b[0;32m   5516\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(categorize)\n\u001b[0;32m   5517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcategorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, split_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 5518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcategorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   5520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\categorical.py:155\u001b[0m, in \u001b[0;36mcategorize\u001b[1;34m(df, columns, index, split_every, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m graph \u001b[38;5;241m=\u001b[39m HighLevelGraph\u001b[38;5;241m.\u001b[39mfrom_collections(prefix, dsk, dependencies\u001b[38;5;241m=\u001b[39m[df])\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Compute the categories\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m categories, index \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_as_if_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# some operations like get_dummies() rely on the order of categories\u001b[39;00m\n\u001b[0;32m    160\u001b[0m categories \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39msort_values() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m categories\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\base.py:369\u001b[0m, in \u001b[0;36mcompute_as_if_collection\u001b[1;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m schedule \u001b[38;5;241m=\u001b[39m get_scheduler(scheduler\u001b[38;5;241m=\u001b[39mscheduler, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, get\u001b[38;5;241m=\u001b[39mget)\n\u001b[0;32m    368\u001b[0m dsk2 \u001b[38;5;241m=\u001b[39m optimization_function(\u001b[38;5;28mcls\u001b[39m)(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\threaded.py:90\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     88\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 90\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\local.py:512\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    510\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[0;32m    514\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\local.py:320\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(exc, tb)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\local.py:225\u001b[0m, in \u001b[0;36mexecute_task\u001b[1;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[1;32m--> 225\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[0;32m    227\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\core.py:127\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    123\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\optimization.py:992\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[1;32m--> 992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\core.py:157\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, out, cache)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[0;32m    156\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[1;32m--> 157\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    159\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\core.py:127\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    123\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\core.py:127\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    123\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\core.py:127\u001b[0m, in \u001b[0;36m_execute_task\u001b[1;34m(arg, cache, dsk)\u001b[0m\n\u001b[0;32m    123\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:96\u001b[0m, in \u001b[0;36mParquetFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(part, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     94\u001b[0m     part \u001b[38;5;241m=\u001b[39m [part]\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_parquet_part\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Temporary workaround for HLG serialization bug\u001b[39;49;00m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# (see: https://github.com/dask/dask/issues/8581)\u001b[39;49;00m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:654\u001b[0m, in \u001b[0;36mread_parquet_part\u001b[1;34m(fs, engine, meta, part, columns, index, kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(part) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m part[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;66;03m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    653\u001b[0m     func \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mread_partition\n\u001b[1;32m--> 654\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtoolz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    664\u001b[0m     df \u001b[38;5;241m=\u001b[39m concat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;66;03m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:655\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(part) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m part[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;66;03m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    653\u001b[0m     func \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mread_partition\n\u001b[0;32m    654\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 655\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtoolz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (rg, kw) \u001b[38;5;129;01min\u001b[39;00m part\n\u001b[0;32m    663\u001b[0m     ]\n\u001b[0;32m    664\u001b[0m     df \u001b[38;5;241m=\u001b[39m concat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;66;03m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:631\u001b[0m, in \u001b[0;36mArrowDatasetEngine.read_partition\u001b[1;34m(cls, fs, pieces, columns, index, dtype_backend, categories, partitions, filters, schema, **kwargs)\u001b[0m\n\u001b[0;32m    628\u001b[0m     row_group \u001b[38;5;241m=\u001b[39m [row_group]\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# Read in arrow table and convert to pandas\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m arrow_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_frag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_read:\n\u001b[0;32m    643\u001b[0m     tables\u001b[38;5;241m.\u001b[39mappend(arrow_table)\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:1764\u001b[0m, in \u001b[0;36mArrowDatasetEngine._read_table\u001b[1;34m(cls, path_or_frag, fs, row_groups, columns, schema, filters, partitions, partition_keys, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     arrow_table \u001b[38;5;241m=\u001b[39m frag\u001b[38;5;241m.\u001b[39mto_table(\n\u001b[0;32m   1758\u001b[0m         use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1759\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   1760\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcols,\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m_filters_to_expression(filters) \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1762\u001b[0m     )\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1764\u001b[0m     arrow_table \u001b[38;5;241m=\u001b[39m \u001b[43m_read_table_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_frag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;66;03m# For pyarrow.dataset api, if we did not read directly from\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;66;03m# fragments, we need to add the partitioned columns here.\u001b[39;00m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partitions \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partitions, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:254\u001b[0m, in \u001b[0;36m_read_table_from_path\u001b[1;34m(path, fs, row_groups, columns, schema, filters, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_input_files(\n\u001b[0;32m    248\u001b[0m     [path],\n\u001b[0;32m    249\u001b[0m     fs\u001b[38;5;241m=\u001b[39mfs,\n\u001b[0;32m    250\u001b[0m     precache_options\u001b[38;5;241m=\u001b[39mprecache_options,\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_file_options,\n\u001b[0;32m    252\u001b[0m )[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mas\u001b[39;00m fil:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row_groups \u001b[38;5;241m==\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m--> 254\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParquetFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfil\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mread_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pq\u001b[38;5;241m.\u001b[39mParquetFile(fil, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpre_buffer)\u001b[38;5;241m.\u001b[39mread_row_groups(\n\u001b[0;32m    262\u001b[0m             row_groups,\n\u001b[0;32m    263\u001b[0m             columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mread_kwargs,\n\u001b[0;32m    267\u001b[0m         )\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\pyarrow\\parquet\\core.py:646\u001b[0m, in \u001b[0;36mParquetFile.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;124;03mRead a Table from Parquet format.\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03manimal: [[\"Flamingo\",\"Parrot\",...,\"Brittle stars\",\"Centipede\"]]\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    644\u001b[0m column_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_column_indices(\n\u001b[0;32m    645\u001b[0m     columns, use_pandas_metadata\u001b[38;5;241m=\u001b[39muse_pandas_metadata)\n\u001b[1;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\pyarrow\\_parquet.pyx:1450\u001b[0m, in \u001b[0;36mpyarrow._parquet.ParquetReader.read_all\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\pyarrow\\types.pxi:88\u001b[0m, in \u001b[0;36mpyarrow.lib._datatype_to_pep3118\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\fsspec\\implementations\\local.py:366\u001b[0m, in \u001b[0;36mLocalFileOpener.read\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = df.categorize(columns = ['LC_CF', 'potential_conflict_type'])\n",
    "\n",
    "df.pivot_table(\n",
    "    index = 'LC_CF',\n",
    "    columns = 'potential_conflict_type',\n",
    "    values = {'TTC', 'MTTC', 'T2', 'TAdv', 'TimeGap', 'ACT',\n",
    "              'PSD', 'DSS', 'MMTC', 'PICUD', 'MTC', 'DRAC', 'MDRAC', 'DCIA', 'unsafety'}, \n",
    "    aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d12d5-e389-4bbe-a4af-8cceb44ceab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de401dfa-2bcc-4d7e-b195-7ddc6af1fd68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.05 GiB for an array with shape (33, 24600754) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실수표현 코드\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mfloat_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat\n\u001b[1;32m----> 4\u001b[0m total_mean \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSSM_list\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;241m0\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m전체\u001b[39m\u001b[38;5;124m'\u001b[39m}, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m sub_mean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mpivot_table(df, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotential_conflict_type\u001b[39m\u001b[38;5;124m'\u001b[39m], values \u001b[38;5;241m=\u001b[39m SSM_list, aggfunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 소계\u001b[39;00m\n\u001b[0;32m      6\u001b[0m each_mean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mpivot_table(df, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotential_conflict_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLC_CF\u001b[39m\u001b[38;5;124m'\u001b[39m], values \u001b[38;5;241m=\u001b[39m SSM_list, aggfunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\pandas\\core\\frame.py:796\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, abc\u001b[38;5;241m.\u001b[39mSequence):\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;66;03m# GH#44616 big perf improvement for e.g. pytorch tensor\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\core.py:618\u001b[0m, in \u001b[0;36m_Frame.__array__\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_computed)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 628\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:96\u001b[0m, in \u001b[0;36mParquetFunctionWrapper.__call__\u001b[1;34m(self, part)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(part, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     94\u001b[0m     part \u001b[38;5;241m=\u001b[39m [part]\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_parquet_part\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Temporary workaround for HLG serialization bug\u001b[39;49;00m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# (see: https://github.com/dask/dask/issues/8581)\u001b[39;49;00m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpiece\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:654\u001b[0m, in \u001b[0;36mread_parquet_part\u001b[1;34m(fs, engine, meta, part, columns, index, kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(part) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m part[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;66;03m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    653\u001b[0m     func \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mread_partition\n\u001b[1;32m--> 654\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtoolz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    664\u001b[0m     df \u001b[38;5;241m=\u001b[39m concat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;66;03m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:655\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(part) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m part[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_multi_support(engine):\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;66;03m# Part kwargs expected\u001b[39;00m\n\u001b[0;32m    653\u001b[0m     func \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mread_partition\n\u001b[0;32m    654\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 655\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtoolz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (rg, kw) \u001b[38;5;129;01min\u001b[39;00m part\n\u001b[0;32m    663\u001b[0m     ]\n\u001b[0;32m    664\u001b[0m     df \u001b[38;5;241m=\u001b[39m concat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m dfs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;66;03m# No part specific kwargs, let engine read\u001b[39;00m\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;66;03m# list of parts at once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:692\u001b[0m, in \u001b[0;36mArrowDatasetEngine.read_partition\u001b[1;34m(cls, fs, pieces, columns, index, dtype_backend, categories, partitions, filters, schema, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    691\u001b[0m         columns_and_parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(columns_and_parts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames))\n\u001b[1;32m--> 692\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns_and_parts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index:\n\u001b[0;32m    695\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(index)\n",
      "File \u001b[1;32mc:\\dev\\python_3.11.6\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    160\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.05 GiB for an array with shape (33, 24600754) and data type float64"
     ]
    }
   ],
   "source": [
    "# 실수표현 코드\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "total_mean = pd.DataFrame(df[SSM_list].mean()).rename({0 : '전체'}, axis = 1)\n",
    "sub_mean = pd.pivot_table(df, columns = ['potential_conflict_type'], values = SSM_list, aggfunc = 'mean') # 소계\n",
    "each_mean = pd.pivot_table(df, columns = ['potential_conflict_type', 'LC_CF'], values = SSM_list, aggfunc = 'mean')\n",
    "\n",
    "#each_mean.loc[:, ('angled', '전체')] = sub_mean['angled'].astype('float16')\n",
    "each_mean.loc[:, ('rear_end', '전체')] = sub_mean['rear_end'].astype('float16')\n",
    "each_mean.loc[:, ('side_swipe', '전체')] = sub_mean['side_swipe'].astype('float16')\n",
    "each_mean.loc[:, ('전체', '전체')] = total_mean\n",
    "\n",
    "total_mean = each_mean.stack().unstack().round(2)\n",
    "total_mean = total_mean[['rear_end', 'side_swipe', '전체']]\n",
    "\n",
    "total_mean.drop([('전체', 'CF'), ('전체', 'LC')], axis = 1, inplace = True)\n",
    "\n",
    "# 카운트\n",
    "total_test = pd.DataFrame(df[['veh_id']].count()).rename({0 : '전체'}, axis = 1)\n",
    "sub_test = pd.pivot_table(df, columns = ['potential_conflict_type'], values = ['veh_id', 'velocity', 'acc'], aggfunc = {'veh_id' : 'count', 'velocity' : 'mean', 'acc' : 'mean'})\n",
    "each_test = pd.pivot_table(df, columns = ['potential_conflict_type', 'LC_CF'], values = ['veh_id', 'velocity', 'acc'], aggfunc = {'veh_id' : 'count', 'velocity' : 'mean', 'acc' : 'mean'})\n",
    "\n",
    "#each_test.loc[:, ('angled', '전체')] = sub_test['angled'].astype('float16')\n",
    "each_test.loc[:, ('rear_end', '전체')] = sub_test['rear_end'].astype('float16')\n",
    "each_test.loc[:, ('side_swipe', '전체')] = sub_test['side_swipe'].astype('float16')\n",
    "each_test.loc[:, ('전체', '전체')] = total_test\n",
    "\n",
    "total_test = each_test.stack().unstack().round(2)\n",
    "#total_test = total_test[['rear_end', 'side_swipe', 'angled', '전체']]\n",
    "\n",
    "total_test.drop([('전체', 'CF'), ('전체', 'LC')], axis = 1, inplace = True)\n",
    "\n",
    "total_mean = pd.concat([total_test, total_mean])\n",
    "total_mean = total_mean.round(2)\n",
    "total_mean = total_mean.astype('float').round(2).fillna('-')\n",
    "\n",
    "total_mean = total_mean.reindex(['veh_id', 'velocity', 'acc'] + SSM_list_1 + SSM_list_2 + SSM_list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f26e5-c5a3-495c-a440-970d192deaaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56402fab-bece-40da-a195-6fc3b2688b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_mean = pd.DataFrame(df[SSM_list].std()).rename({0 : '전체'}, axis = 1)\n",
    "sub_mean = pd.pivot_table(df, columns = ['potential_conflict_type'], values = SSM_list, aggfunc = np.std) # 소계\n",
    "each_mean = pd.pivot_table(df, columns = ['potential_conflict_type', 'LC_CF'], values = SSM_list, aggfunc = np.std)\n",
    "\n",
    "#each_mean.loc[:, ('angled', '전체')] = sub_mean['angled'].astype('float16')\n",
    "each_mean.loc[:, ('rear_end', '전체')] = sub_mean['rear_end'].astype('float16')\n",
    "each_mean.loc[:, ('side_swipe', '전체')] = sub_mean['side_swipe'].astype('float16')\n",
    "each_mean.loc[:, ('전체', '전체')] = total_mean\n",
    "\n",
    "total_mean = each_mean.stack().unstack().round(2)\n",
    "total_mean = total_mean[['rear_end', 'side_swipe', '전체']]\n",
    "\n",
    "total_mean.drop([('전체', 'CF'), ('전체', 'LC')], axis = 1, inplace = True)\n",
    "\n",
    "# 카운트\n",
    "\n",
    "total_test = pd.DataFrame(df[['veh_id']].count()).rename({0 : '전체'}, axis = 1)\n",
    "sub_test = pd.pivot_table(df, columns = ['potential_conflict_type'], values = ['veh_id', 'velocity', 'acc'], aggfunc = {'veh_id' : 'count', 'velocity' : np.std, 'acc' : np.std})\n",
    "each_test = pd.pivot_table(df, columns = ['potential_conflict_type', 'LC_CF'], values = ['veh_id', 'velocity', 'acc'], aggfunc = {'veh_id' : 'count', 'velocity' : np.std, 'acc' : np.std})\n",
    "\n",
    "#each_test.loc[:, ('angled', '전체')] = sub_test['angled'].astype('float16')\n",
    "each_test.loc[:, ('rear_end', '전체')] = sub_test['rear_end'].astype('float16')\n",
    "each_test.loc[:, ('side_swipe', '전체')] = sub_test['side_swipe'].astype('float16')\n",
    "each_test.loc[:, ('전체', '전체')] = total_test\n",
    "\n",
    "total_test = each_test.stack().unstack().round(2)\n",
    "#total_test = total_test[['rear_end', 'side_swipe', 'angled', '전체']]\n",
    "\n",
    "total_test.drop([('전체', 'CF'), ('전체', 'LC')], axis = 1, inplace = True)\n",
    "\n",
    "total_mean = pd.concat([total_test, total_mean])\n",
    "total_mean = total_mean.round(2)\n",
    "total_mean = total_mean.astype('float').round(2).fillna('-')\n",
    "\n",
    "total_mean = total_mean.reindex(['veh_id', 'velocity', 'acc'] + SSM_list_1 + SSM_list_2 + SSM_list_3)\n",
    "\n",
    "total_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c1eb2-a6b9-4772-92e9-d01d4626f919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb09e9b-2a4a-42ea-8799-4c7ca291d4c5",
   "metadata": {},
   "source": [
    "# 히트맵 또는 산점도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffdb4bc-95af-4a62-abf6-d0aa04c7591e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['cell'] = df['local_x'].apply(make_cell)\n",
    "# 셀별 차로변경 횟수(Leave) : 이는 sum으로 구하면 된다.\n",
    "cell_list = df['cell'].unique()\n",
    "cell_list.sort()\n",
    "cell_list = list(cell_list)\n",
    "\n",
    "\n",
    "for target_SSM_list, name in zip([SSM_list_1, SSM_list_2, SSM_list_3], ['Time-based SSM', 'Distance_based SSM', 'Deceleration_based SSM']):\n",
    "    \n",
    "    fig = make_subplots(rows = len(target_SSM_list), cols = 1)\n",
    "\n",
    "    for SSM, i in zip(target_SSM_list, range(1, len(target_SSM_list)+1)):\n",
    "\n",
    "        if name == 'Time-based SSM':\n",
    "            sec = df[(df[SSM] <= 10)]\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "#         V_df = sec[['local_x', 'lane', SSM]]\n",
    "#         LV_df = sec[['LV_local_x', 'LV_lane', SSM]]\n",
    "#         LV_df.rename({'LV_local_x' : 'local_x', 'LV_lane' : 'lane'}, axis = 1, inplace = True)\n",
    "#         VLV_df = pd.concat([V_df, LV_df])\n",
    "#         VLV_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#         VLV_df['cell'] = VLV_df['local_x'].apply(make_cell)\n",
    "\n",
    "        if len(sec) > 0:\n",
    "\n",
    "            pv_veh = pd.pivot_table(sec,\n",
    "                       index = 'lane',\n",
    "                        columns = 'cell',\n",
    "                        values = [SSM],\n",
    "                        aggfunc = {SSM : 'mean'})\n",
    "\n",
    "            if len(pv_veh) > 0:\n",
    "\n",
    "                pv_veh = pv_veh[SSM]\n",
    "\n",
    "                for cell in cell_list:\n",
    "                    if cell not in pv_veh.columns:\n",
    "                        pv_veh[cell] = np.NaN # 만약 셀이 없으면 추가해야 한다.\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                pv_veh.reset_index(inplace = True)\n",
    "                # 컬럼을 셀 번호 이름대로 정렬해준다. 이때 절때 Heatmap의 Categoryascending을 해 주면 안된다는 것이다.\n",
    "                pv_veh2 = pv_veh[cell_list + ['lane']]\n",
    "                #print(pv_veh2)\n",
    "\n",
    "                if SSM in ['TTC', 'T2', 'ACT', 'MTTC']:\n",
    "                    ax = go.Heatmap(df_to_plotly(pv_veh2.round(2)),\n",
    "                                colorscale = palette_TTC,\n",
    "                                texttemplate = '%{z}',\n",
    "                                textfont = {'size' : 10},\n",
    "                                showlegend = False,\n",
    "                                zmin = 0, zmax = 10\n",
    "                                )\n",
    "                    \n",
    "                elif SSM in ['TAdv', 'TimeGap']:\n",
    "                    ax = go.Heatmap(df_to_plotly(pv_veh2.round(2)),\n",
    "                                colorscale = palette_TTC,\n",
    "                                texttemplate = '%{z}',\n",
    "                                textfont = {'size' : 10},\n",
    "                                showlegend = False,\n",
    "                                zmin = 0, zmax = 3\n",
    "                                )\n",
    "\n",
    "                elif SSM in ['PSD', 'MTC', 'MMTC']: # 값이 낮을수록 위험\n",
    "                    ax = go.Heatmap(df_to_plotly(pv_veh2.round(2)),\n",
    "                                    colorscale = palette_TTC,\n",
    "                                    texttemplate = '%{z}',\n",
    "                                    textfont = {'size' : 10},\n",
    "                                    showlegend = False,\n",
    "                                    zmin = 0, zmax = 1\n",
    "                                                        )\n",
    "\n",
    "                elif SSM in ['DSS', 'PICUD']:\n",
    "                    ax = go.Heatmap(df_to_plotly(pv_veh2.round(2)),\n",
    "                                    colorscale = palette_TTC,\n",
    "                                    texttemplate = '%{z}',\n",
    "                                    textfont = {'size' : 10},\n",
    "                                    showlegend = False,\n",
    "                                    zmin = -30, zmax = 0\n",
    "                                                        )\n",
    "\n",
    "                elif SSM in ['DRAC', 'MDRAC', 'DCIA']:\n",
    "                    ax = go.Heatmap(df_to_plotly(pv_veh2.round(2)),\n",
    "                                    colorscale = palette_TIT,\n",
    "                                    texttemplate = '%{z}',\n",
    "                                    textfont = {'size' : 10},\n",
    "                                    showlegend = False,\n",
    "                                    zmin = 3.4, zmax = 50\n",
    "                                                        )\n",
    "\n",
    "                elif SSM in ['unsafety']:\n",
    "                    ax = go.Heatmap(df_to_plotly(pv_veh2.round(2)),\n",
    "                                    colorscale = palette_TTC,\n",
    "                                    texttemplate = '%{z}',\n",
    "                                    textfont = {'size' : 10},\n",
    "                                    showlegend = False,\n",
    "                                    zmax = 0, zmin = -10\n",
    "                                                        )\n",
    "\n",
    "                else:\n",
    "                    print(SSM, 'What')\n",
    "\n",
    "                fig.add_trace(ax, i, 1) # i행 j열에 추가\n",
    "                print('added!')\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    fig.update_xaxes(matches = 'x')\n",
    "    fig.update_yaxes(matches = 'y')\n",
    "\n",
    "    fig.update_layout(yaxis = dict(autorange = 'reversed'), \n",
    "              height = 1200, width = 1200,\n",
    "              template = 'simple_white',\n",
    "                     title_text = f'{name}')\n",
    "\n",
    "    fig.update(layout_showlegend = False)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9535c1-f3fc-4db9-8c9b-7c9cd002933f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 바이올린"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e45f7-ae4b-4daf-aa70-07f49b08e901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title_list = ['Time-based SSM', 'Distance-based SSM', 'Deceleration-based SSM']\n",
    "scale = 'count' # area, width\n",
    "\n",
    "for target_SSM_list, title in zip([SSM_list_1, SSM_list_2, SSM_list_3], title_list):\n",
    "    \n",
    "    target_len = 6#len(target_SSM_list)\n",
    "    \n",
    "    fig = plt.figure(figsize = (4 * target_len, 3))\n",
    "\n",
    "    for SSM, i in tqdm(zip(target_SSM_list, range(target_len))):\n",
    "\n",
    "        fig.add_subplot(1, target_len+1, i+1)\n",
    "        \n",
    "        # 임계값 불러오기\n",
    "        tdx = np.where(threshold_list == SSM)[0][0]\n",
    "        threshold = threshold_list[tdx][1]\n",
    "\n",
    "        if SSM == 'ACT':\n",
    "            upper_bound = 50\n",
    "            lower_bound = 0\n",
    "            \n",
    "            tdf = df_0[(df_0[SSM] >= lower_bound) & (df_0[SSM] <= upper_bound)].dropna(subset = SSM).copy()\n",
    "        \n",
    "        elif SSM in SSM_list_1:\n",
    "            #tdf = df_0[(df_0[SSM] <= 30) & (df_0[SSM] >= 0)].dropna(subset = SSM).copy()\n",
    "            upper_bound = 100\n",
    "            lower_bound = 0\n",
    "            \n",
    "            tdf = df_0[(df_0[SSM] >= lower_bound) & (df_0[SSM] <= upper_bound)].dropna(subset = SSM).copy()\n",
    "\n",
    "        else:\n",
    "            upper_bound = df_0[SSM].mean() + df_0[SSM].std() * 3\n",
    "            lower_bound = df_0[SSM].mean() - df_0[SSM].std() * 3\n",
    "            \n",
    "            tdf = df_0[(df_0[SSM] >= lower_bound) & (df_0[SSM] <= upper_bound)].dropna(subset = SSM).copy()\n",
    "\n",
    "\n",
    "        tdf['potential_conflict_type'] = tdf['potential_conflict_type'].map({'rear_end': 'Rear-end', 'side_swipe' : 'Side-swipe'})\n",
    "        tdf['Behavior'] = tdf['LC_CF'].map({'CF': 'Car-following', 'LC' : 'Lane change'})\n",
    "\n",
    "\n",
    "        if SSM in SSM_list_1:\n",
    "            \n",
    "            sec = pd.DataFrame({'potential_conflict_type' : ['Rear-end', 'Side-swipe']})\n",
    "            tdf = pd.concat([tdf, sec])\n",
    "            tdf = tdf.sort_values(by = 'LC_CF', ascending = False)\n",
    "\n",
    "            ax = sns.violinplot(\n",
    "                data = tdf,\n",
    "                x = 'potential_conflict_type', y = SSM,\n",
    "                hue = 'Behavior',\n",
    "                bw = 0.2,\n",
    "                linewidth = 0.9,\n",
    "                scale = scale,\n",
    "                split = True,\n",
    "                palette = \"Pastel1\",\n",
    "                cut = 0, inner = 'quart',\n",
    "                order = ['Rear-end', 'Side-swipe']\n",
    "            )\n",
    "            \n",
    "            # 플롯에 텍스트 달기\n",
    "            \n",
    "            for l in ax.lines:\n",
    "                ax.text(l.get_data()[0][l.get_data()[0].nonzero()][0], l.get_data()[1][0], f'{l.get_data()[1][0]:.2f}')\n",
    "\n",
    "\n",
    "        elif SSM in SSM_list_2:\n",
    "            # ax = sns.histplot(\n",
    "            #     data = tdf,\n",
    "            #     y = SSM,\n",
    "            #     hue = 'Behavior', \n",
    "            #     #stat = 'density',\n",
    "            #     kde = True, bins = 50,\n",
    "            #     linewidth = 0.5, edgecolor = 'white',\n",
    "            #     palette = \"Pastel1\",\n",
    "            #     line_kws = {'linewidth' : 1.5}\n",
    "            # )\n",
    "            \n",
    "            sec = pd.DataFrame({'potential_conflict_type' : ['Rear-end', 'Side-swipe']})\n",
    "            tdf = pd.concat([tdf, sec])\n",
    "            \n",
    "            tdf = tdf.sort_values(by = 'LC_CF', ascending = False)\n",
    "            \n",
    "            ax = sns.violinplot(\n",
    "                data = tdf,\n",
    "                x = 'potential_conflict_type', y = SSM,\n",
    "                hue = 'Behavior',\n",
    "                bw = 0.2,\n",
    "                linewidth = 0.9,\n",
    "                scale = scale,\n",
    "                split = True,\n",
    "                palette = \"Pastel1\",\n",
    "                inner = 'quart',\n",
    "                order = ['Rear-end', 'Side-swipe']\n",
    "            )\n",
    "            # 플롯에 텍스트 달기\n",
    "            \n",
    "            for l in ax.lines:\n",
    "                ax.text(l.get_data()[0][l.get_data()[0].nonzero()][0], l.get_data()[1][0], f'{l.get_data()[1][0]:.2f}')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            temp_dict = {'DRAC' : [0, 10], 'MDRAC' : [0, 5], 'DCIA' : [-10, 10], 'unsafety' : [-10, 10]}\n",
    "            \n",
    "            tdf = tdf[(tdf[SSM] >= temp_dict[SSM][0]) & (tdf[SSM] <= temp_dict[SSM][1])]\n",
    "            \n",
    "            sec = pd.DataFrame({'potential_conflict_type' : ['Rear-end', 'Side-swipe']})\n",
    "            tdf = pd.concat([tdf, sec])\n",
    "            tdf = tdf.sort_values(by = 'LC_CF', ascending = False)\n",
    "            \n",
    "            # ax = sns.histplot(\n",
    "            #     data = tdf,\n",
    "            #     y = SSM,\n",
    "            #     hue = 'Behavior', \n",
    "            #     #stat = 'density',\n",
    "            #     kde = True, bins = 50,\n",
    "            #     linewidth = 0.5, edgecolor = 'white',\n",
    "            #     palette = \"Pastel1\",\n",
    "            #     line_kws = {'linewidth' : 1.5})\n",
    "            ax = sns.violinplot(\n",
    "                data = tdf,\n",
    "                x = 'potential_conflict_type', y = SSM,\n",
    "                hue = 'Behavior',\n",
    "                bw = 0.2,\n",
    "                linewidth = 0.9,\n",
    "                scale = scale,\n",
    "                split = True,\n",
    "                palette = \"Pastel1\",\n",
    "                inner = 'quart',\n",
    "                order = ['Rear-end', 'Side-swipe']\n",
    "            )\n",
    "            \n",
    "            # 플롯에 텍스트 달기\n",
    "            \n",
    "            for l in ax.lines:\n",
    "                ax.text(l.get_data()[0][l.get_data()[0].nonzero()][0], l.get_data()[1][0], f'{l.get_data()[1][0]:.2f}')\n",
    "                \n",
    "            #ax.set_ylim([temp_dict[SSM][0], temp_dict[SSM][1]])\n",
    "\n",
    "        # 임계값을 설정해 주기\n",
    "        plt.axhline(y = threshold, color = 'black', linestyle = '--', linewidth = 0.5, label = f'Threshold {threshold}')\n",
    "\n",
    "        #ax.legend_.remove()\n",
    "\n",
    "        # Add title and labels\n",
    "        plt.title(f'{SSM}')\n",
    "\n",
    "        if SSM in SSM_list_1:\n",
    "            #plt.yticks(np.arange(0, 11))\n",
    "            plt.xlabel('Conflict type')\n",
    "            plt.ylabel(f'{SSM}')\n",
    "            plt.legend(fontsize = 9)\n",
    "            \n",
    "        else:\n",
    "            #ax.set_yscale('log')\n",
    "            #plt.yscale('symlog')\n",
    "            plt.xlabel('Conflict type')\n",
    "            plt.ylabel(f'{SSM}')\n",
    "            plt.legend(fontsize = 9, loc = 'upper right')\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    ## ----------------------------------------------------------------------\n",
    "    #이미지 저장하기\n",
    "\n",
    "    save_file = f'violin_merging_{title}.png'\n",
    "    save_folder = 'Dataset/04_graph'\n",
    "    save_path = os.path.join(working_dir, save_folder, save_file)\n",
    "\n",
    "    plt.savefig(save_path, dpi = 300)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a3645-58b0-40d6-8054-676341f47aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kur = pd.DataFrame(df_0[SSM_list].kurt()).rename({0 : 'Kurtosis'}, axis = 1)\n",
    "kur['Skewness'] = pd.DataFrame(df_0[SSM_list].skew()).rename({0 : 'Skewness'}, axis = 1)['Skewness']\n",
    "kur = kur.round(2)\n",
    "kur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e60433-f657-4fe9-ac3c-426b3eff4f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 문제차량 SSM 2-Dimensional Profile 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00acf693-f1e5-458e-81e0-bc7c597d686e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_0[['Lane_record', 'LV_Lane_record']].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e34c3-52e5-4ebf-8518-7ff53be12a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[(df['Lane_record'] == 'U07_U06_U05_U04') & (df['LV_Lane_record'] == 'U05_U06_U08')].drop_duplicates(subset = ['veh_id', 'LV_ID']).sort_values(by = ['veh_id'])[['veh_id', 'LV_ID', 'LV_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7bbbf-2538-44b1-b833-70cf4d265bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df['veh_id'] == '1900'][['LV_ID', 'LV_type']].drop_duplicates().sort_values(by = 'LV_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7e35b-6080-4de8-b418-f995040a96a7",
   "metadata": {},
   "source": [
    "## Time-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a3ca8-27e4-4e49-bf8a-2eb639cc2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7d2df-42f8-4bc5-8fce-c34daacffe00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_0\n",
    "scatter_size = 12\n",
    "\n",
    "Vehicle_ID, LV_ID = 1900, 1888\n",
    "x_min, x_max = 150, 550\n",
    "\n",
    "# Vehicle_ID, LV_ID = '1428', '1425'\n",
    "# x_min, x_max = 200, 400\n",
    "\n",
    "# Vehicle_ID, LV_ID = '714', '710'\n",
    "# x_min, x_max = 200, 600\n",
    "\n",
    "# Vehicle_ID, LV_ID = '63', '62'\n",
    "# x_min, x_max = 200, 600\n",
    "\n",
    "for target_SSM_list, title in tqdm(zip([SSM_list_1, SSM_list_2, SSM_list_3], ['Time-based SSM', 'Distance-based SSM', 'Deceleration-based SSM'])):\n",
    "    \n",
    "    fig = plt.figure(figsize = (5, 10))\n",
    "    row_num = len(SSM_list_1)+3\n",
    "\n",
    "    if target_SSM_list != SSM_list_3:\n",
    "\n",
    "        gs = fig.add_gridspec(row_num, 1, height_ratios = (3, 1, 1, 1, 1, 1, 1, 1, 1), hspace = 1.2) # 5행 1열의 그리드 생성\n",
    "\n",
    "    else:\n",
    "        gs = fig.add_gridspec(row_num, 1, height_ratios = (3, 1, 1, 1, 1, 1, 1, 1, 1), hspace = 1.2) # 5행 1열의 그리드 생성\n",
    "\n",
    "    # 대상 차량 쌍을 필터링하여, 프레임별로 정렬하기\n",
    "    sec1 = df[df['pair'] == f'{veh_id}_{LV_ID}']\n",
    "    sec2 = df[df['pair'] == f'{LV_ID}_{veh_id}']\n",
    "\n",
    "    # TV, LV가 역전된 sec2 DF의 경우, 컬럼이름을 바꾸어주어야 한다.\n",
    "    col_list = ['local_x', 'local_y', 'velocity', 'acc', 'lane', 'Time', 'local_x_before',\n",
    "           'local_y_before', 'delta_local_x', 'delta_local_y', 'velocity_x',\n",
    "           'velocity_y', 'velocity_x_before', 'velocity_y_before',\n",
    "           'delta_velocity_x', 'delta_velocity_y', 'acc_x', 'acc_y', 'lane_past',\n",
    "           'Lane_record', 'Lane_record_split', 'Lane_00', 'Lane_99', 'Lane_change',\n",
    "           'Lane_leave', 'Lane_change_direction']\n",
    "\n",
    "    for col in col_list:\n",
    "        sec2.rename({col:f'LV2_{col}'}, axis = 1, inplace = True)\n",
    "        sec2.rename({f'LV_{col}' : col}, axis = 1, inplace = True)\n",
    "        sec2.rename({f'LV2_{col}':f'LV_{col}'}, axis = 1, inplace = True)\n",
    "\n",
    "    sec2.rename({'V_len' : 'LV_len', 'V_wid' : 'LV_wid', 'LV_wid' : 'V_wid', 'LV_len' : 'V_len'}, axis = 1, inplace = True)\n",
    "\n",
    "    sample = pd.concat([sec1, sec2])\n",
    "    sample = sample.sort_values(by = ['frm']).dropna(subset = 'local_x')\n",
    "    sample = sample.reset_index(drop = True)\n",
    "\n",
    "    ## 대상차량 궤적 표시\n",
    "    V_x = np.array(sample['local_x'])\n",
    "    V_y = np.array(sample['local_y'])\n",
    "    V_time = np.array(sample['Time'])\n",
    "\n",
    "    V_vx = np.array(sample['velocity_x'])\n",
    "    V_vy = np.array(sample['velocity_y'])\n",
    "    \n",
    "    test = px.colors.sequential.Turbo[::-1]\n",
    "    gradient_list = np.array(test)\n",
    "\n",
    "    ## 선행차량 궤적 표시\n",
    "    LV_x = np.array(sample['LV_local_x'])\n",
    "    LV_y = np.array(sample['LV_local_y'])\n",
    "\n",
    "    LV_vx = np.array(sample['LV_velocity_x'])\n",
    "    LV_vy = np.array(sample['LV_velocity_y'])\n",
    "\n",
    "\n",
    "    # 차량 사이즈\n",
    "    V_len = np.nanmax(sample[sample['veh_id'] == veh_id]['V_len'])\n",
    "    V_wid = np.nanmax(sample[sample['veh_id'] == veh_id]['V_wid'])\n",
    "    LV_len = np.nanmax(sample[sample['LV_ID'] == LV_ID]['LV_len'])\n",
    "    LV_wid = np.nanmax(sample[sample['LV_ID'] == LV_ID]['LV_wid'])\n",
    "\n",
    "    # 서브플롯 생성\n",
    "    for row in range(0, row_num):\n",
    "        globals()[f'ax_{row}_0'] = fig.add_subplot(gs[row, 0]) # row행 col열에 서브플롯 생성\n",
    "        globals()[f'ax_{row}_0'].set_xlim(25, 250) # 가로축 통일\n",
    "\n",
    "    # 첫 플롯에만 백그라운드 궤적 생성하기\n",
    "\n",
    "    globals()[f'ax_0_0'].plot(V_x, V_y, c = 'blue', linewidth = 1, alpha = 0.5)\n",
    "    globals()[f'ax_0_0'].plot(LV_x, LV_y, c = 'black', linewidth = 1, alpha = 0.5)\n",
    "\n",
    "    # globals()[f'ax_0_0'].scatter(V_x, V_y, c = 'lightgray', marker = 'o', s = scatter_size/4)\n",
    "    # globals()[f'ax_0_0'].scatter(LV_x, LV_y, c = 'lightgray', marker = '^', s = scatter_size/4)\n",
    "\n",
    "    globals()[f'ax_0_0'].axis('equal')\n",
    "    globals()[f'ax_0_0'].set_xlim(25, 250) # 가로축 통일\n",
    "    globals()[f'ax_0_0'].set_ylim(0, 30)\n",
    "    globals()[f'ax_0_0'].set_ylabel('Y (m)', size = 9)\n",
    "\n",
    "\n",
    "    # 가장 위 플롯에만 1초 간격으로 연결하기, 차량의 상대적 위치 표시하기\n",
    "\n",
    "    V_time = np.array(sample['Time'])\n",
    "    V_time_label = np.array((sample['Time'] - np.nanmin(V_time)).round(2))\n",
    "\n",
    "    time_min = math.ceil(np.nanmin(V_time_label))\n",
    "    time_max = math.floor(np.nanmax(V_time_label))\n",
    "    \n",
    "    time_list = [0.1] + list(range(1, time_max+1)) #  + [np.nanmax(V_time_label)]\n",
    "\n",
    "    for i, ikk in zip(time_list, range(len(time_list))):\n",
    "\n",
    "        # t == i일때의 인덱스 반환 \n",
    "        if len(np.where(V_time_label == i)[0]) > 0:\n",
    "            idx = np.where(V_time_label == i)[0][0]\n",
    "            #print(np.where(V_time_label == i)[0], i, idx)\n",
    "            #print(i, idx)\n",
    "            gradient = gradient_list[ikk]\n",
    "            #lobals()[f'ax_0_0'].plot([V_x[idx], LV_x[idx]], [V_y[idx], LV_y[idx]], c = gradient, linewidth = 0.5)\n",
    "\n",
    "            local_x = V_x[idx]\n",
    "            LV_local_x = LV_x[idx]\n",
    "\n",
    "            local_y = V_y[idx]\n",
    "            LV_local_y = LV_y[idx]\n",
    "\n",
    "            V_velocity_x = V_vx[idx]\n",
    "            V_velocity_y = V_vy[idx]\n",
    "\n",
    "            LV_velocity_x = LV_vx[idx]\n",
    "            LV_velocity_y = LV_vy[idx]\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(local_y, LV_local_y, local_x, LV_local_x)\n",
    "            # 차량의 상대적 위치관계를 직선으로 연결하고, t = x 를 화살표로 표시하기\n",
    "\n",
    "            if round(i)%2 == 0 : # i가 짝수이면 위에 notation\n",
    "                globals()[f'ax_0_0'].annotate(f't={round(i)}', \n",
    "                            xy = (V_x[idx], V_y[idx]), \n",
    "                            xytext = (V_x[idx]+5, V_y[idx]+15), color = gradient,\n",
    "                            arrowprops = dict(facecolor = gradient, arrowstyle = '-|>', linestyle = ':', edgecolor = gradient))\n",
    "\n",
    "                globals()[f'ax_0_0'].annotate(f'', \n",
    "                            xy = (LV_x[idx], LV_y[idx]), \n",
    "                            xytext = (V_x[idx]+7, V_y[idx]+12), color = gradient,\n",
    "                            arrowprops = dict(facecolor = gradient, arrowstyle = '-|>', linestyle = ':', edgecolor = gradient))\n",
    "\n",
    "            else: #i가 홀수이면\n",
    "                globals()[f'ax_0_0'].annotate(f't={round(i)}', \n",
    "                            xy = (V_x[idx], V_y[idx]), \n",
    "                            xytext = (V_x[idx]+13, V_y[idx]-15), color = gradient,\n",
    "                            arrowprops = dict(facecolor = gradient, arrowstyle = '-|>', linestyle = ':', edgecolor = gradient))\n",
    "\n",
    "                globals()[f'ax_0_0'].annotate(f'', \n",
    "                            xy = (LV_x[idx], LV_y[idx]), \n",
    "                            xytext = (V_x[idx]+20, V_y[idx]-12), color = gradient,\n",
    "                            arrowprops = dict(facecolor = gradient, arrowstyle = '-|>', linestyle = ':', edgecolor = gradient))\n",
    "\n",
    "\n",
    "            ## 각 t = x 점에서 차량의 위치를 선으로 그리기\n",
    "\n",
    "            #print(i, idx, V_velocity_x, LV_velocity_x)\n",
    "\n",
    "            if pd.isna(V_velocity_x) == False and pd.isna(LV_velocity_x) == False:\n",
    "                \n",
    "                r1 = patches.Rectangle((local_x-1/2*V_len, local_y-1/2*V_wid), V_len, V_wid, color = gradient, alpha = 1) # TV 위치\n",
    "                r2 = patches.Rectangle((LV_local_x-1/2*LV_len, LV_local_y-1/2*V_wid), LV_len, LV_wid, color = gradient,  alpha = 1)\n",
    "                \n",
    "                rotate_angle_1 = math.atan(V_velocity_y/V_velocity_x)\n",
    "                rotate_angle_2 = math.atan(LV_velocity_y/LV_velocity_x)\n",
    "                \n",
    "                if V_velocity_y >= 0:\n",
    "                    sign_1 = 1\n",
    "                else:\n",
    "                    sign_1 = -1\n",
    "                    \n",
    "                if LV_velocity_y >= 0:\n",
    "                    sign_2 = 1\n",
    "                else:\n",
    "                    sign_2 = -1\n",
    "                \n",
    "                t1 = mpl.transforms.Affine2D().rotate_deg(sign_1 * rotate_angle_1) + globals()[f'ax_0_0'].transData\n",
    "                r1.set_transform(t1)\n",
    "                \n",
    "                t2 = mpl.transforms.Affine2D().rotate_deg(sign_2 * rotate_angle_2) + globals()[f'ax_0_0'].transData\n",
    "                r2.set_transform(t2)\n",
    "                \n",
    "                globals()[f'ax_0_0'].add_patch(r1)\n",
    "                globals()[f'ax_0_0'].add_patch(r2)\n",
    "                \n",
    "                if local_y > LV_local_y: # 만약 TV가 LV보다 위에 있으면                \n",
    "                    globals()[f'ax_0_0'].text(local_x, local_y+3, 'V1', color = 'black', size = 8)\n",
    "                    globals()[f'ax_0_0'].text(LV_local_x, LV_local_y-7, 'V2', color = 'black', size = 8)\n",
    "                    \n",
    "                else:\n",
    "                    globals()[f'ax_0_0'].text(local_x, local_y-7, 'V1', color = 'black', size = 8)\n",
    "                    globals()[f'ax_0_0'].text(LV_local_x, LV_local_y+3, 'V2', color = 'black', size = 8)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    ## -----------------------------------------------------------------------------------------------\n",
    "\n",
    "    # 두 번째 플롯에 상대거리(D), 상충유형, LC-CF 추가하기\n",
    "    D = abs(sample['D'])\n",
    "    globals()[f'ax_1_0'].set_title(f'Distance between vehicle pair', size = 9)\n",
    "    globals()[f'ax_1_0'].scatter(V_x, D, marker = 'o', color = 'gray', s = scatter_size/4)\n",
    "    globals()[f'ax_1_0'].set_ylabel('Gap distance(m)', size = 9)\n",
    "    \n",
    "    for conftype, clr in zip(['rear_end', 'side_swipe', 'angled'], ['blue', 'red', 'orange']):\n",
    "        tick = sample[(sample['potential_conflict_type'] == conftype)]\n",
    "        tick_D = tick['D']\n",
    "        tick_x = tick['local_x']\n",
    "        globals()[f'ax_1_0'].scatter(tick_x, tick_D, marker = 'o', color = clr, s = scatter_size/4, label = conftype)\n",
    "        #globals()[f'ax_1_0'].legend(loc = 'upper right')\n",
    "    \n",
    "    #globals()[f'ax_1_0'].legend(loc = 'upper right', fontsize = 8)\n",
    "    globals()[f'ax_1_0'].set_ylim(0, np.nanmax(D)+10) # 세로축 통일\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##-----------------------------------------------------------------------------------------------\n",
    "    # 세번째 플롯에 두 차량의 속도와 LC-CF를 표기하기\n",
    "    \n",
    "    globals()[f'ax_2_0'].set_title(f'Velocity of vehicle pair', size = 9)\n",
    "    \n",
    "    for LC_CF, clr in zip(['CF', 'LC'], ['blue', 'skyblue']): # LC_CF에 따라서 다른 마커모양을 적용하시오\n",
    "        tick = sample[sample['LC_CF'] == LC_CF]\n",
    "        tick_V_x = tick['local_x']\n",
    "        tick_V_v = tick['velocity_x']\n",
    "    \n",
    "        globals()[f'ax_2_0'].scatter(tick_V_x, tick_V_v, marker = 'x', color = clr, s = scatter_size/2, label = 'V1')\n",
    "        \n",
    "    for LC_CF, clr in zip(['CF', 'LC'], ['gray', 'lightgray']): # LC_CF에 따라서 다른 마커모양을 적용하시오\n",
    "        tick = sample[sample['LV_LC_CF'] == LC_CF]\n",
    "        tick_LV_x = tick['LV_local_x']\n",
    "        tick_LV_v = tick['LV_velocity_x']\n",
    "    \n",
    "        globals()[f'ax_2_0'].scatter(tick_LV_x, tick_LV_v, marker = 'o', color = clr, s = scatter_size/2, label = 'V2')\n",
    "    \n",
    "    globals()[f'ax_2_0'].set_ylim(50, 130) # 가로축 통일\n",
    "    globals()[f'ax_2_0'].set_ylabel('Speed(km/h)', size = 9)\n",
    "    \n",
    "    \n",
    "    ## ------------------------------------------------------------------------------------------------\n",
    "    # 각 SSM을 그리기 : 각 행별로\n",
    "\n",
    "    ## Time-based\n",
    "\n",
    "    for SSM, row in zip(target_SSM_list, range(0, row_num)): # Time-based 면 1행에 집어넣는다\n",
    "\n",
    "        tdx = np.where(threshold_list == SSM)[0][0]\n",
    "        threshold = threshold_list[tdx][1]\n",
    "\n",
    "        V_ssm = np.array(sample[SSM])\n",
    "        \n",
    "        if len(V_ssm[np.isnan(V_ssm) == False]) > 0: # SSM 값이 최소 1개 이상 존재하면\n",
    "\n",
    "\n",
    "            # SSM 값에 따른 색상스케일 설정\n",
    "            ## 임계값이 존재하고, 값이 0 이상이며, 임계값보다 작을수록 위험할 시\n",
    "            if SSM in ['TTC', 'T2', 'MTTC', 'ACT', 'TAdv', 'TimeGap']:\n",
    "                divnorm = colors.TwoSlopeNorm(vmin = 0, vcenter = threshold, vmax = 20)\n",
    "                globals()[f'ax_{row+3}_0'].set_title(f'[{SSM}] Threshold : {threshold}', size = 9) # , The lower the value, the higher the risk\n",
    "                #globals()[f'ax_{row+3}_0'].axhspan(0, threshold, alpha = 0.1, color = 'gray')\n",
    "\n",
    "                globals()[f'ax_{row+3}_0'].scatter(V_x, V_ssm, c = V_ssm, \n",
    "                marker = 'o', edgecolor = 'gray', linewidth = 0.5,  s = scatter_size,\n",
    "                       cmap = 'RdBu', norm = divnorm,\n",
    "                       label = 'Following Vehicle')\n",
    "                \n",
    "                globals()[f'ax_{row+3}_0'].set_ylim([0, 20])\n",
    "\n",
    "\n",
    "                # 임계값 아래인 지점에는 붉은색 X표시를 하기\n",
    "                danger_V_x = np.array(sample[sample[SSM] < threshold]['local_x'])\n",
    "                danger_V_ssm = np.array(sample[sample[SSM] < threshold][SSM])\n",
    "                \n",
    "                for dvx in danger_V_x:\n",
    "                    globals()[f'ax_{row+3}_0'].axvspan(dvx-0.5, dvx+0.5, color = 'red', alpha = 0.1)\n",
    "                    \n",
    "                globals()[f'ax_{row+3}_0'].scatter(danger_V_x, danger_V_ssm, marker = 'x', c = danger_V_ssm, cmap = 'RdBu', norm = divnorm, s = 20, label = 'Danger')\n",
    "                \n",
    "                \n",
    "            elif SSM in ['PSD']:\n",
    "                divnorm = colors.TwoSlopeNorm(vmin = 0, vcenter = threshold, vmax = 2)\n",
    "                globals()[f'ax_{row+3}_0'].set_title(f'[{SSM}] Threshold : {threshold}', size = 9) # , The lower the value, the higher the risk\n",
    "                #globals()[f'ax_{row+3}_0'].axhspan(0, threshold, alpha = 0.1, color = 'gray')\n",
    "\n",
    "                globals()[f'ax_{row+3}_0'].scatter(V_x, V_ssm, c = V_ssm, \n",
    "                marker = 'o', edgecolor = 'gray', linewidth = 0.5,  s = scatter_size,\n",
    "                       cmap = 'RdBu', norm = divnorm,\n",
    "                       label = 'Following Vehicle')\n",
    "                \n",
    "                globals()[f'ax_{row+3}_0'].set_ylim([0, 2])\n",
    "\n",
    "\n",
    "                # 임계값 아래인 지점에는 붉은색 X표시를 하기\n",
    "                danger_V_x = np.array(sample[sample[SSM] < threshold]['local_x'])\n",
    "                danger_V_ssm = np.array(sample[sample[SSM] < threshold][SSM])\n",
    "                \n",
    "                for dvx in danger_V_x:\n",
    "                    globals()[f'ax_{row+3}_0'].axvspan(dvx-0.5, dvx+0.5, color = 'red', alpha = 0.1)\n",
    "                    \n",
    "                globals()[f'ax_{row+3}_0'].scatter(danger_V_x, danger_V_ssm, marker = 'x', c = danger_V_ssm, cmap = 'RdBu', norm = divnorm, s = 20, label = 'Danger')\n",
    "                \n",
    "\n",
    "            ## 임계값이 있고, 바닥이 없으며, 임계값보다 작을수록 위험할 시\n",
    "            elif SSM in ['PICUD', 'DSS', 'MTC', 'MMTC', 'unsafety']:\n",
    "                divnorm = colors.TwoSlopeNorm(vmin = np.nanmin([-1, np.nanmin(V_ssm)]), vcenter = threshold, vmax = np.nanmax([2, np.nanmax(V_ssm)]))\n",
    "                globals()[f'ax_{row+3}_0'].set_title(f'[{SSM}] Threshold : {threshold}', size = 9) # , The lower the value, the higher the risk\n",
    "                #globals()[f'ax_{row+3}_0'].axhspan(threshold, np.min([-1, np.nanmin(V_ssm)]), alpha = 0.1, color = 'gray')\n",
    "\n",
    "                globals()[f'ax_{row+3}_0'].scatter(V_x, V_ssm, c = V_ssm, \n",
    "                marker = 'o', edgecolor = 'gray', linewidth = 0.5,  s = scatter_size,\n",
    "                       cmap = 'RdBu', norm = divnorm,\n",
    "                       label = 'Following Vehicle')\n",
    "\n",
    "                    \n",
    "                # 임계값 아래인 지점에는 붉은색 X표시를 하기\n",
    "                danger_V_x = np.array(sample[sample[SSM] < threshold]['local_x'])\n",
    "                danger_V_ssm = np.array(sample[sample[SSM] < threshold][SSM])\n",
    "                \n",
    "                for dvx in danger_V_x:\n",
    "                    globals()[f'ax_{row+3}_0'].axvspan(dvx-0.5, dvx+0.5, color = 'red', alpha = 0.1)                \n",
    "\n",
    "                globals()[f'ax_{row+3}_0'].scatter(danger_V_x, danger_V_ssm, marker = 'x', c = danger_V_ssm, cmap = 'RdBu', norm = divnorm, s = 20, label = 'Danger')\n",
    "                \n",
    "\n",
    "            ## 임계값이 있고, 이보다 클수록 위험할 경우\n",
    "            elif SSM in ['DRAC', 'MDRAC', 'DCIA']:\n",
    "                divnorm = colors.TwoSlopeNorm(vmin = np.nanmin([0, np.nanmin(V_ssm)]), vcenter = threshold, vmax = threshold + 5)\n",
    "                globals()[f'ax_{row+3}_0'].set_title(f'[{SSM}] Threshold : {threshold}', size = 9) #, The higher the value, the higher the risk'\n",
    "                #globals()[f'ax_{row+3}_0'].axhspan(threshold, np.nanmax([np.nanmax(V_ssm), 5]), alpha = 0.1, color = 'gray')\n",
    "\n",
    "                globals()[f'ax_{row+3}_0'].scatter(V_x, V_ssm, c = V_ssm, \n",
    "                marker = 'o', edgecolor = 'gray', linewidth = 0.5,  s = scatter_size,\n",
    "                       cmap = 'coolwarm', norm = divnorm,\n",
    "                       label = 'Following Vehicle')\n",
    "\n",
    "                    \n",
    "                # 임계값 위인 지점에는 붉은색 X표시를 하기\n",
    "                danger_V_x = np.array(sample[sample[SSM] > threshold]['local_x'])\n",
    "                danger_V_ssm = np.array(sample[sample[SSM] > threshold][SSM])\n",
    "                \n",
    "                for dvx in danger_V_x:\n",
    "                    globals()[f'ax_{row+3}_0'].axvspan(dvx-0.5, dvx+0.5, color = 'red', alpha = 0.1)    \n",
    "                    \n",
    "                globals()[f'ax_{row+3}_0'].scatter(danger_V_x, danger_V_ssm, marker = 'x', c = danger_V_ssm, cmap = 'coolwarm', norm = divnorm, s = 20, label = 'Danger')\n",
    "\n",
    "\n",
    "            ## 그 외\n",
    "            else:\n",
    "                divnorm = colors.TwoSlopeNorm(vmin = np.nanmin([0, np.nanmin(V_ssm)]), vcenter = threshold, vmax = threshold + 5)\n",
    "\n",
    "                globals()[f'ax_{row+3}_0'].scatter(V_x, V_ssm, c = V_ssm, \n",
    "                marker = 'o', edgecolor = 'gray', linewidth = 0.5,  s = scatter_size,\n",
    "                       cmap = 'turbo', norm = divnorm,\n",
    "                       label = 'Following Vehicle')\n",
    "\n",
    "\n",
    "            # 플롯에 축 설정\n",
    "            globals()[f'ax_{row+3}_0'].set_ylabel(SSM, size = 8)\n",
    "\n",
    "            # 플롯에 임계값을 가로선으로 그려준다\n",
    "            globals()[f'ax_{row+3}_0'].axhline(y = threshold, color = 'red', linestyle = '--', linewidth = 0.5, label = f'Threshold = {threshold}')\n",
    "            #globals()[f'ax_{row+1}_0'].text(30, np.nanmean([np.nanmin([0, np.nanmin(V_ssm)]), np.nanmax(V_ssm)]), f'Threshold : {threshold}', color = 'red', size = 8)\n",
    "            \n",
    "            #globals()[f'ax_{row+1}_0'].legend([], [f'Threshold : {threshold}'],loc = 'upper right', fontsize = 8)\n",
    "            \n",
    "        else: # SSM 값이 하나도 없으면\n",
    "            globals()[f'ax_{row+3}_0'].set_title(f'[{SSM}] Threshold : {threshold}', size = 9) #, The higher the value, the higher the risk'\n",
    "            globals()[f'ax_{row+3}_0'].set_ylabel(SSM, size = 8)\n",
    "            globals()[f'ax_{row+3}_0'].text(130, 0.4, 'None', color = 'black', size = 8)\n",
    "\n",
    "\n",
    "    # 가장 아래에 X(m) 라고 거리 표시\n",
    "    globals()[f'ax_{row_num-1}_0'].set_xlabel('X (m)', size = 9)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## ----------------------------------------------------------------------\n",
    "    #이미지 저장하기\n",
    "    \n",
    "    save_file = f'merging_{veh_id}_{LV_ID}_{title}.png'\n",
    "    save_folder = 'Dataset/04_graph'\n",
    "    save_path = os.path.join(working_dir, save_folder, save_file)\n",
    "    \n",
    "    plt.savefig(save_path, dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
